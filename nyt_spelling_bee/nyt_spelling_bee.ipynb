{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67eb7565-fcae-47b6-ae6d-023bdcd256dc",
   "metadata": {},
   "source": [
    "# Overview: NYT Spelling Bee Helper\n",
    "\n",
    "**Game:** \"Spelling Bee\" is a New York Times daily puzzle game where a player is given a list of 7 letters arranged in a honeycomb shape with one central hexagon and 6 surrounding hexagons. Using the central letter at least once, players must form as many 4+ character words as possible with the list. Duplicate letters are allowed and words are restricted, presumably, to the English language. NYT doesn't post their word source, so we can't be sure of what words are and aren't playable.\n",
    "\n",
    "**Exercise:** Create a class that accepts the daily set of words and contains functions to output answers.\n",
    "\n",
    "**Caveats:**\n",
    "- Words must be in an English dictionary\n",
    "    - We'll use the list of words stored on macOS in usr/share/dict/web2\n",
    "        - any word with a capital letter will be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b71b8b6-c04f-4cdc-ac03-e7f8fdff1c70",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d920fa-62af-4e8d-8a96-a688f9992d9c",
   "metadata": {},
   "source": [
    "### Inspect MacOS Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8606a5-281e-42fa-a7b7-86961e7df468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: ['aalii', 'Aani', 'aardvark', 'aardwolf', 'Aaron']\n",
      "Sample 2: ['absently', 'absentment', 'absentmindedly', 'absentness', 'absfarad', 'abshenry', 'Absi', 'absinthe']\n",
      "Sample 3: ['Aleurodes', 'Aleurodidae', 'aleuromancy', 'aleurometer', 'aleuronat', 'aleurone', 'aleuronic', 'aleuroscope']\n"
     ]
    }
   ],
   "source": [
    "# word list of 4+ words\n",
    "with open('web2.txt', 'r') as f:\n",
    "    words = [x for x in f.read().split('\\n') if len(x)>3]\n",
    "    print('Sample 1:', words[0:5])\n",
    "    print('Sample 2:', words[500:508])\n",
    "    print('Sample 3:', words[5000:5008])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295849d-f42b-41ae-b14b-dc83a9a36f41",
   "metadata": {},
   "source": [
    "We'll want to remove capital letters, but outside of this the list appears to be all set. Some of the words seem like they may not be words in the English language. We'll cross reference the final list using a Webster Dictionary API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54189915-4613-4972-bb0d-bdc2c08e3dc0",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bae6c-84ae-4b93-83f7-376c3c39c3da",
   "metadata": {},
   "source": [
    "### Import Required Packages\n",
    "- Effort was made to keep the import list lightweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce0fa51-3cea-423d-af4c-bea958429068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import string\n",
    "import ast\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556f4d34-4a09-41be-aac0-53c5b5decb29",
   "metadata": {},
   "source": [
    "### Create Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93933bc-973b-4b36-9953-eddf16b1b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellingBee:\n",
    "    \n",
    "    # Assign variables on instantiation\n",
    "    def __init__(self, letters, center_letter, api_key=None, word_list=None, min_length=4):\n",
    "        \n",
    "        # Assign letters, letters_list, not_letters_list, center_letter, api_key\n",
    "        if isinstance(letters, str):\n",
    "            letters_list = [x for x in list(letters) if x.isalpha() and x.islower()]\n",
    "            if len(letters_list)==7:\n",
    "                self.letters = letters\n",
    "                self.letters_list = letters_list\n",
    "                self.not_letters_list = (set(string.ascii_lowercase) - set(letters_list))\n",
    "                self.center_letter = center_letter\n",
    "                self.api_key = api_key\n",
    "            else:\n",
    "                raise Exception('Provided string must only contain a-z and be length=7')\n",
    "        else:\n",
    "            raise Exception('Provided string must be in \"abcdefg\" format')\n",
    "            \n",
    "        # Assign word_list\n",
    "        if word_list:\n",
    "            self.word_list = word_list\n",
    "            warnings.warn('Warning: Custom list being used. Ensure elements meet desired length and format requirements.')\n",
    "        else:\n",
    "            try: \n",
    "                with open('web2.txt', 'r') as f:\n",
    "                    self.word_list = [x for x in f.read().split('\\n') if len(x)>=min_length and x.islower()]\n",
    "                    f.close()\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "                \n",
    "    def dictionary_check(self, word):\n",
    "        # URL and request\n",
    "        url = f'https://dictionaryapi.com/api/v3/references/collegiate/json/{word}?key={self.api_key}' \n",
    "        r = requests.get(url)\n",
    "        \n",
    "        return json.loads(r.content)\n",
    "\n",
    "    def remove_letters(self):\n",
    "        \n",
    "        # Convert word list to string representation\n",
    "        string_word_list = str(self.word_list)\n",
    "        \n",
    "        # Remove characters that cannot be used\n",
    "        for char in self.not_letters_list:\n",
    "            string_word_list = string_word_list.replace(char, '')\n",
    "        \n",
    "        # Initial pruned word list\n",
    "        pruned_word_list = ast.literal_eval(string_word_list)\n",
    "        \n",
    "        # Remove words that do no contain center letter\n",
    "        pruned_word_list = [word for word in pruned_word_list if self.center_letter in word]\n",
    "        \n",
    "        return pruned_word_list\n",
    "    \n",
    "    def matching_words(self):\n",
    "        \n",
    "        # Matching words will be the intersection of pruned list and word list\n",
    "        matches = list(set(self.remove_letters()).intersection(set(self.word_list)))\n",
    "        sorted_matches = sorted(matches, key=lambda x: -1*len(x))\n",
    "        \n",
    "        return sorted_matches\n",
    "    \n",
    "    def verified_matching_words(self):\n",
    "        \n",
    "        # Verify sorted matches against webster api; if the API returns a populated list then the word is a match \n",
    "        verified_matches = [match for match in self.matching_words() if self.dictionary_check(match)]\n",
    "        \n",
    "        return verified_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d4ee6e-c24c-4393-aa17-38a25a6f3a70",
   "metadata": {},
   "source": [
    "### Run w/ Daily Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cea12f2-dc27-4e6a-bb6e-38ab2f856d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFIED:\n",
      "\n",
      "['unconvincing', 'unconniving', 'gonococcic', 'convincing', 'unvoicing', 'nonunion', 'unionic', 'nooning', 'voicing', 'nogging', 'cogging', 'conning', 'ingoing', 'ongoing', 'inconnu', 'coining', 'gunong', 'cooing', 'nuncio', 'novcic', 'cocoon', 'uncoin', 'coving', 'iconic', 'nonion', 'gonion', 'noncon', 'congou', 'nonoic', 'noggin', 'ninon', 'oncin', 'incog', 'conic', 'nonic', 'conin', 'going', 'covin', 'coign', 'cocci', 'cogon', 'onion', 'cocco', 'ionic', 'union', 'inion', 'unco', 'conn', 'coco', 'icon', 'coon', 'coin', 'niog', 'gong', 'unio', 'goon', 'cion', 'vino', 'gogo', 'noun', 'noon']\n",
      "\n",
      "\n",
      "\n",
      "UNVERIFIED:\n",
      "\n",
      "['unconvincing', 'unconniving', 'gonococcic', 'convincing', 'unvoicing', 'nonunion', 'unionic', 'nooning', 'voicing', 'nogging', 'cogging', 'conning', 'ingoing', 'ongoing', 'inconnu', 'coining', 'gunong', 'cooing', 'nuncio', 'novcic', 'cocoon', 'uncoin', 'coving', 'iconic', 'nonion', 'gonion', 'noncon', 'congou', 'nonoic', 'noggin', 'ninon', 'oncin', 'incog', 'conic', 'nonic', 'conin', 'going', 'covin', 'coign', 'cocci', 'cogon', 'onion', 'cocco', 'ionic', 'union', 'inion', 'unco', 'conn', 'coco', 'icon', 'coon', 'coin', 'niog', 'gong', 'unio', 'goon', 'cion', 'vino', 'gogo', 'noun', 'noon']\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 2.82 s, sys: 221 ms, total: 3.04 s\n",
      "Wall time: 9.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "api_key = os.environ['API_KEY']\n",
    "\n",
    "# Instantiate class object with daily word list and api key\n",
    "bee = SpellingBee('vinoucg', 'o', api_key)\n",
    "\n",
    "# Check for verified matching words\n",
    "print('VERIFIED:\\n')\n",
    "print(bee.verified_matching_words())\n",
    "print('\\n\\n')\n",
    "\n",
    "# Compare list to non-verified matching words\n",
    "print('UNVERIFIED:\\n')\n",
    "print(bee.matching_words())\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be768a6d-cc90-4d2e-985c-65874985531e",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a5213-56d5-47fc-beaf-0c7278edbceb",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae652a-ff14-47db-981d-0ce772d424ab",
   "metadata": {},
   "source": [
    "Interestingly, the verified and unverified lists are exactly the same, so it must be the case that macOS relies largely (if not wholly) on Webster's Collegiate Dictionary or something similar. Many of these words are not acceptable answers in NYT Spelling Bee, meaning that NYT uses yet another dictionary as its game basis. \n",
    "\n",
    "With this in mind, it makes more sense to use the matching_words() function when using the macOS word list, expecially since the API verification process does not permit batch calls making it rather slow. Custom word lists are better suited for verification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352079e-e6d6-41bf-bac7-ffb197b22ea7",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
